{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90788d06",
   "metadata": {},
   "source": [
    "# Preprocessing Dataset for NLP Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ddbe76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading in required modules \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41e535",
   "metadata": {},
   "source": [
    "### Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b72a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>raw_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17981</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Best Baltic Amber Teething Necklace For Baby (...</td>\n",
       "      <td>Love this necklace</td>\n",
       "      <td>Love this necklace!!! My daughter is almost a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Badger Basket Five Basket Storage Unit with Wi...</td>\n",
       "      <td>Baskets are not even toy quality</td>\n",
       "      <td>We purchased this for our church nursery. This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12908</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>iPazzPort 2.4GHz Mini Wireless Fly Keyboard wi...</td>\n",
       "      <td>Excellent and convenient</td>\n",
       "      <td>I have an HTPC (Home Theater Personal Computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3M WorkTunes Hearing Protector, MP3 Compatible...</td>\n",
       "      <td>makes a static sound</td>\n",
       "      <td>I would not recommend this, unless it was free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Perfecto 100% Pure Badger Shaving Brush-Silver...</td>\n",
       "      <td>Nice Shavinf brush</td>\n",
       "      <td>I got this one as a gift from perfecto for bei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  RATING  VERIFIED_PURCHASE  PRODUCT_CATEGORY  \\\n",
       "17981      1       5                  1                 2   \n",
       "941        0       3                  0                 2   \n",
       "12908      1       5                  1                 0   \n",
       "2573       0       2                  0                17   \n",
       "4519       0       5                  0                 4   \n",
       "\n",
       "                                           PRODUCT_TITLE  \\\n",
       "17981  Best Baltic Amber Teething Necklace For Baby (...   \n",
       "941    Badger Basket Five Basket Storage Unit with Wi...   \n",
       "12908  iPazzPort 2.4GHz Mini Wireless Fly Keyboard wi...   \n",
       "2573   3M WorkTunes Hearing Protector, MP3 Compatible...   \n",
       "4519   Perfecto 100% Pure Badger Shaving Brush-Silver...   \n",
       "\n",
       "                           REVIEW_TITLE  \\\n",
       "17981                Love this necklace   \n",
       "941    Baskets are not even toy quality   \n",
       "12908          Excellent and convenient   \n",
       "2573               makes a static sound   \n",
       "4519                 Nice Shavinf brush   \n",
       "\n",
       "                                            raw_sentence  \n",
       "17981  Love this necklace!!! My daughter is almost a ...  \n",
       "941    We purchased this for our church nursery. This...  \n",
       "12908  I have an HTPC (Home Theater Personal Computer...  \n",
       "2573   I would not recommend this, unless it was free...  \n",
       "4519   I got this one as a gift from perfecto for bei...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in csv (Source - https://www.kaggle.com/lievgarcia/amazon-reviews)\n",
    "df = pd.read_csv(r\"C:\\Machine Learning\\UU\\amazon_reviews.csv\", encoding = \"latin\")\n",
    "\n",
    "# Fixing Labels \n",
    "df = df.rename(columns={\"ï»¿LABEL\":\"class\", \"REVIEW_TEXT\":\"raw_sentence\"})\n",
    "\n",
    "# Re-labeling data for increased accessibility \n",
    "# Mapping to binary \n",
    "df[\"class\"] = df[\"class\"].map({\"__label1__\": 0, \"__label2__\": 1})\n",
    "df[\"VERIFIED_PURCHASE\"] = df[\"VERIFIED_PURCHASE\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# Converting categorical data to numerical\n",
    "df[\"PRODUCT_CATEGORY\"] = pd.factorize(df[\"PRODUCT_CATEGORY\"])[0]\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2acb0",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312abf5",
   "metadata": {},
   "source": [
    "- Punctuation removal \n",
    "- Tokenising \n",
    "- Parts of Speech Tagging \n",
    "- Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20281043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b85b0ace97f46ceb69b64342ef6c872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def punc_remove(text):\n",
    "    \"\"\"\n",
    "    Removing punctuation \n",
    "    \"\"\"\n",
    "    punc = list(string.punctuation)\n",
    "    \n",
    "    punc_free = \"\".join([i for i in text if i not in punc])\n",
    "    \n",
    "    return punc_free\n",
    "\n",
    "df[\"raw_sentence\"] = df[\"raw_sentence\"].progress_apply(lambda x:punc_remove(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a0d491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84056e6782f146529c212648ef6d4073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenise(text = df[\"raw_sentence\"]):\n",
    "    # Creating word tokens in lower case\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return tokens \n",
    "\n",
    "df[\"token_sentence\"] = df[\"raw_sentence\"].progress_apply(lambda x:tokenise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56092ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671eb8f86faf42a6bc1881e9799b8b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pos_tokens(tokens = df[\"token_sentence\"]):\n",
    "    \"\"\"\n",
    "    Returns tokenised and tagged words\n",
    "    Required pre-process for nltk lemmatizing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tagging using nltk \n",
    "    pos_token = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Replacing tags with tags accepted by lemmatiser \n",
    "    for i, (word, tag) in enumerate(pos_token):\n",
    "        # Adjectives\n",
    "        if tag.startswith(\"J\"):\n",
    "             tag = wordnet.ADJ\n",
    "        # Verbs \n",
    "        elif tag.startswith(\"V\"):\n",
    "             tag = wordnet.VERB\n",
    "        # Nouns \n",
    "        elif tag.startswith(\"N\"):\n",
    "             tag = wordnet.NOUN\n",
    "        # Adverbs \n",
    "        elif tag.startswith(\"R\"):\n",
    "             tag = wordnet.ADV\n",
    "        else:\n",
    "             tag = \"\"\n",
    "        # Replacing tags \n",
    "        pos_token[i] = (word, tag)\n",
    "    \n",
    "    return pos_token\n",
    "\n",
    "# Applying function to entire dataset \n",
    "df[\"pos_tagged_sentence\"] = df[\"token_sentence\"].progress_apply(lambda x: pos_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d406bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16176588f051425291813e7c021633dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7212     [product, permit, take, pleasure, yard, refill...\n",
       "34       [bag, look, like, little, small, version, one,...\n",
       "3954     [light, receive, bright, color, different, loo...\n",
       "12538    [many, think, pirate, favorite, letter, 34r34,...\n",
       "20539    [buy, two, cover, center, thread, pandora, bra...\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "\n",
    "def get_all_lemmas(pos_tokens = df[\"pos_tagged_sentence\"]):\n",
    "    # Creating empty list\n",
    "    lemmatized_list = []\n",
    "    stop = stopwords.words(\"english\")\n",
    "    \n",
    "    # Loop through all tagged sentences\n",
    "    for sentence in tqdm(pos_tokens):\n",
    "        sent = []\n",
    "        # Loop through all words and POS tag\n",
    "        for word, tag in sentence:\n",
    "            if tag in [\"a\", \"r\", \"n\", \"v\"] and word not in stop:\n",
    "                # Only nouns, adverbs, adjectives and verbs have lemma form\n",
    "                lemma = lm.lemmatize(word, tag)\n",
    "                sent.append(lemma)\n",
    "            elif word not in stop:\n",
    "                # Keeping non-stop words (NLP useful)\n",
    "                lemma = word\n",
    "                sent.append(lemma)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        lemmatized_list.append(sent)\n",
    "    \n",
    "    # Adding lemmas to dataframe \n",
    "    df[\"lemmatized\"] = lemmatized_list\n",
    "    \n",
    "    return df[\"lemmatized\"].sample(5)\n",
    "\n",
    "get_all_lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b07c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns \n",
    "df = df.drop([\"PRODUCT_TITLE\", \"REVIEW_TITLE\", \"token_sentence\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26954947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>raw_sentence</th>\n",
       "      <th>pos_tagged_sentence</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13213</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I chose 5 stars because this product is usuall...</td>\n",
       "      <td>[(i, n), (chose, v), (5, ), (stars, n), (becau...</td>\n",
       "      <td>[choose, 5, star, product, usually, expensive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17976</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>B button on backside of wheel does not work un...</td>\n",
       "      <td>[(b, ), (button, n), (on, ), (backside, n), (o...</td>\n",
       "      <td>[b, button, backside, wheel, work, unless, cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12362</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>this is a Christmas gift for one of my grandso...</td>\n",
       "      <td>[(this, ), (is, v), (a, ), (christmas, a), (gi...</td>\n",
       "      <td>[christmas, gift, one, grandson, hope, enjoy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>My cousin just bought tubes Its great and come...</td>\n",
       "      <td>[(my, ), (cousin, n), (just, r), (bought, v), ...</td>\n",
       "      <td>[cousin, buy, tubes, great, come, consistent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19655</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>My old Clarks sandals were much better and las...</td>\n",
       "      <td>[(my, ), (old, a), (clarks, a), (sandals, n), ...</td>\n",
       "      <td>[old, clarks, sandal, much, good, last, long, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  RATING  VERIFIED_PURCHASE  PRODUCT_CATEGORY  \\\n",
       "13213      1       5                  1                 5   \n",
       "17976      1       2                  0                22   \n",
       "12362      1       5                  1                22   \n",
       "6099       0       5                  0                20   \n",
       "19655      1       3                  1                19   \n",
       "\n",
       "                                            raw_sentence  \\\n",
       "13213  I chose 5 stars because this product is usuall...   \n",
       "17976  B button on backside of wheel does not work un...   \n",
       "12362  this is a Christmas gift for one of my grandso...   \n",
       "6099   My cousin just bought tubes Its great and come...   \n",
       "19655  My old Clarks sandals were much better and las...   \n",
       "\n",
       "                                     pos_tagged_sentence  \\\n",
       "13213  [(i, n), (chose, v), (5, ), (stars, n), (becau...   \n",
       "17976  [(b, ), (button, n), (on, ), (backside, n), (o...   \n",
       "12362  [(this, ), (is, v), (a, ), (christmas, a), (gi...   \n",
       "6099   [(my, ), (cousin, n), (just, r), (bought, v), ...   \n",
       "19655  [(my, ), (old, a), (clarks, a), (sandals, n), ...   \n",
       "\n",
       "                                              lemmatized  \n",
       "13213  [choose, 5, star, product, usually, expensive,...  \n",
       "17976  [b, button, backside, wheel, work, unless, cra...  \n",
       "12362  [christmas, gift, one, grandson, hope, enjoy, ...  \n",
       "6099   [cousin, buy, tubes, great, come, consistent, ...  \n",
       "19655  [old, clarks, sandal, much, good, last, long, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee25053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle to not lose functionality of dataframe\n",
    "df.to_pickle(\"labelled_data_preprocessed.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
